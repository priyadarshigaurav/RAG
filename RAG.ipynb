{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required Libraries\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using groq framework for loading LLM model\n",
    "groq_api_key = \"gsk_bhFeDUr4Ly9XFB9IwGmaWGdyb3FYlvQTsc8S7TQH4MXNTxxxxxx\"\n",
    "llm = ChatGroq(groq_api_key=groq_api_key, model_name=\"llama3-70b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\priya\\Desktop\\Quantiphie\\RAG\\myenvi\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Using Huggingface for embedding documents\n",
    "embeddings = HuggingFaceBgeEmbeddings(\n",
    "                model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "                model_kwargs={'device': 'cpu'},\n",
    "                encode_kwargs={'normalize_embeddings': True}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 615 documents.\n",
      "Splited into 155 chunks.\n",
      "Vector embeddings Started.\n",
      "Vector embeddings created.\n",
      "Vector embeddings Saved.\n"
     ]
    }
   ],
   "source": [
    "#For Creating and saving the vectors using faissdb\n",
    "FAISS_INDEX_PATH = \"faiss_index_temp\" #Path for Saving and loading vectors\n",
    "loader = PyPDFDirectoryLoader(r\"PDF_DOC\")  # Data Ingestion from given directory\n",
    "docs = loader.load()  # Document Loading\n",
    "print(f\"Loaded {len(docs)} documents.\")\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)  # Chunk Creation\n",
    "final_documents = text_splitter.split_documents(docs[5:54]) #Using 5 and 54 for selecting Chap 1-2 \n",
    "print(f\"Splited into {len(final_documents)} chunks.\")\n",
    "\n",
    "if not final_documents:\n",
    "    print(\"No final documents available for embeddings.\")\n",
    "    \n",
    "print(\"Vector embeddings Started.\")\n",
    "\n",
    "vectors = FAISS.from_documents(final_documents, embeddings)  # Vector embeddings\n",
    "print(\"Vector embeddings created.\")\n",
    "\n",
    "vectors.save_local(FAISS_INDEX_PATH)\n",
    "print(\"Vector embeddings Saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For loading saved Vector Embeddings\n",
    "FAISS_INDEX_PATH = r\"faiss_index\"\n",
    "vectors = FAISS.load_local(folder_path=FAISS_INDEX_PATH,embeddings = embeddings,allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LLM Input prompt template\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "\"\"\"\n",
    "Answer the questions based on the provided context only.\n",
    "Please provide the most accurate response based on the question\n",
    "<context>\n",
    "{context}\n",
    "<context>\n",
    "Questions: {input}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_chain = create_stuff_documents_chain(llm, prompt) # Combining LLM and Input prompt together\n",
    "retriever = vectors.as_retriever() #Creating retrievers from the faiss vector database. A retriever is an interface that returns documents given an unstructured query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_chain = create_retrieval_chain(retriever, document_chain) # Creating Chains so as to have sequences of calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Isotopes are different forms of the same element that have the same number of protons, but a different number of neutrons.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Invoking call on the created chain with the input question\n",
    "ques = \"What are isotopes?\"\n",
    "response = retrieval_chain.invoke({'input': ques.lower()})\n",
    "response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on the provided context, I'll do my best to answer your questions:\\n\\n1. What is the atomic number of hydrogen?\\n\\nThe context doesn't explicitly mention the atomic number of hydrogen. However, it does explain that the atomic number of an element is equal to the number of protons it contains. Since hydrogen is not discussed in the context of its atomic structure, we cannot determine its atomic number from the provided information.\\n\\n2. Calculate the atomic mass of carbon.\\n\\nAccording to the context, the mass number (or atomic mass) of an element is the sum of its protons and neutrons. For carbon-12, the context states that it has 6 protons and 6 neutrons, resulting in a mass number of 12. Therefore, the atomic mass of carbon-12 is 12.\\n\\nFor carbon-14, it has 6 protons and 8 neutrons, resulting in a mass number of 14. Therefore, the atomic mass of carbon-14 is 14.\\n\\nNote that the context doesn't provide a general formula or a single value for the atomic mass of carbon, as it has different isotopes with varying mass numbers.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ques = \"What is the atomic number of hydrogen. ALso calsulate the atomic mass of the carbon.\"\n",
    "response = retrieval_chain.invoke({'input': ques.lower()})\n",
    "response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
